{"cells":[{"cell_type":"markdown","metadata":{"id":"-WzDzKYt7tkK"},"source":["# Agent"]},{"cell_type":"markdown","source":["# LLM alapú Ágens készítése a MedQuad adatbázishoz.\n","\n","A MedQuad (Medical Question Answering Dataset) egy angol nyelvű orvosi adatbázis, amelyet elsősorban mesterséges intelligencia és természetes nyelvi feldolgozás (NLP) kutatásokhoz fejlesztettek ki. Ez az adatbázis kérdés-válasz párokat tartalmaz, amelyek orvosi témákra fókuszálnak, és célja, hogy segítse az automatizált rendszereket abban, hogy pontos és megbízható válaszokat adjanak egészségügyi kérdésekre. Az adatbázis tartalma általában orvosi szakirodalomból, klinikai információkból és hiteles forrásokból származik, például a National Institutes of Health (NIH) vagy más elismert egészségügyi szervezetek publikációiból."],"metadata":{"id":"wzhtVsoo-2cL"}},{"cell_type":"markdown","source":["## Függőségek telepítése"],"metadata":{"id":"340ftwAh-5aS"}},{"cell_type":"code","source":["!pip install llama-index llama-index-embeddings-huggingface llama-index-llms-huggingface bitsandbytes"],"metadata":{"id":"pEpafAld_E9C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Csomagok importálása"],"metadata":{"id":"Z95iS8rd_KBV"}},{"cell_type":"code","source":["import os\n","import kagglehub\n","import pandas as pd\n","\n","from tqdm import tqdm\n","\n","from llama_index.core import Settings\n","from llama_index.core import Document\n","from llama_index.core import StorageContext\n","from llama_index.core import VectorStoreIndex\n","from llama_index.core import load_index_from_storage\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","\n","from matplotlib import pyplot as plt"],"metadata":{"id":"061P23RY_Flq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download latest version\n","path = kagglehub.dataset_download(handle=\"googleai/dataset-metadata-for-cord19\")\n","\n","print(\"Path to dataset files:\", path)"],"metadata":{"id":"SdEcJNeT_Qi6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(path)"],"metadata":{"id":"Z2ktoElTSM81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filename_with_path = path + \"/\" + os.listdir(path)[0]\n","filename_with_path"],"metadata":{"id":"d1BAkUyySQvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_meta_cord19 = pd.read_csv(filename_with_path)\n","df_meta_cord19.head()"],"metadata":{"id":"joSSL56LSVDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_meta_cord19.info()"],"metadata":{"id":"ekQ2EHHGSW3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_meta_cord19_filtered = df_meta_cord19[df_meta_cord19['description'].notnull()]\n","df_meta_cord19_filtered.info()"],"metadata":{"id":"iu-IXCiYSdqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a vector database using the LlamaIndex function library."],"metadata":{"id":"E0zwH0BM_V0K"}},{"cell_type":"code","source":[],"metadata":{"id":"zSR6xviX_zQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create Agent"],"metadata":{"id":"4UfEF0iC_zm9"}},{"cell_type":"code","source":["# Létrehozzuk a nyelvi modellt (LLM), amit az ágens fog használni.\n","llm = HuggingFaceLLM(\n","    model_name=\"colesmcintosh/Llama-3.2-1B-Instruct-Mango\",       # Nyelvi modell beállítása\n","    tokenizer_name=\"colesmcintosh/Llama-3.2-1B-Instruct-Mango\",   # Nyelvi modell tokenizátorának beállítása\n","    context_window=2048,                                          # Maximum token limit\n","    max_new_tokens=256,                                           # Válasz maximális hossza\n","    device_map=\"cuda:0\",                                          # GPU használata,\n","    generate_kwargs={\"temperature\": 0.95, \"do_sample\": True},     # Ezek a paraméterek befolyásolják a modell válaszainak véletlenszerűségét és kreativitását.\n",")"],"metadata":{"id":"PMh5Jjk4_XxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Settings.llm = llm"],"metadata":{"id":"cv6qvCva_5Ed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Létrehozzuk a chat motort, ami az ágens párbeszédéért felelős.\n","chat_engine = index.as_chat_engine(\n","    # Ez a paraméter beállítja, hogy a chat motor a korábban létrehozott vektoradatbázist használja a válaszokhoz.\n","    chat_mode=\"context\",\n","    # Ez a paraméter beállítja a chat motor memóriáját. A ChatMemoryBuffer emlékszik a korábbi beszélgetésekre.\n","    memory=ChatMemoryBuffer.from_defaults(token_limit=32000),\n","    # Ez a paraméter beállítja a rendszerüzenetet, ami az ágens viselkedését befolyásolja. Ebben az esetben az ágens egy orvosi chatbot, amely a MedQuad adathalmaz alapján válaszol.\n","    system_prompt=(\n","        \"You are a medical chatbot, able to have normal interactions. You only answre based on MedQuad dataset.\"\n","    )\n",")"],"metadata":{"id":"omxOcLxp_9ob"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ez egy végtelen ciklus, ami lehetővé teszi, hogy folyamatosan kérdéseket tegyünk fel az ágensnek.\n","while True:\n","  query = input(\"> \")                                     # Bekérjük a felhasználótól a kérdést.\n","  if query.lower() == \"quit\":                             # Ha a felhasználó azt írja, hogy \"quit\", akkor a ciklus megszakad.\n","      break\n","\n","  # Streamelt válasz\n","  print(\"Agent: \", end=\"\", flush=True)                    # Kiírjuk, hogy az ágens válaszolni fog.\n","  response = chat_engine.stream_chat(query)               # Ez a sor elküldi a kérdést a chat motornak, és megkapjuk a választ.\n","  for token in response.response_gen:                     # Ez a ciklus kiírja a választ részleteiben (tokenekként) streamelve.\n","      print(token, end=\"\", flush=True)\n","  print()                                                 # Egy új sort írunk ki a válasz után.\n","\n","chat_engine.reset()                                       # History törlése"],"metadata":{"id":"W5yDb6V3ABwa"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}