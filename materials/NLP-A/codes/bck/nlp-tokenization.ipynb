{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zysf6Ss4H0h0"
      },
      "source": [
        "# Tokeniz√°ci√≥\n",
        "\n",
        "- A mondatok szavakra, sz√≥r√©szekre vagy karakterekre t√∂rt√©n≈ë darabol√°sa\n",
        "- Fajt√°i:\n",
        "    - Karakter alap√∫\n",
        "    - Sz√≥, alsz√≥ alap√∫\n",
        "- C√©l: A feldolgozni k√≠v√°nt adathalmaz szavakra vagy karakterekre t√∂rt√©n≈ë t√∂rdel√©se olyan m√≥don hogy az anal√≠zishez felhaszn√°lt g√©pi tanul√≥ elj√°r√°s a saj√°t sz√≥t√°ra seg√≠ts√©g√©vel azt beazonos√≠tani tudja.\n",
        "- Trade-off: m√©ret vs hat√©konys√°g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J99-eFwUG7k",
        "outputId": "71d23bb8-53fb-433e-9d52-035368179c35"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtFbC4F-H0h7"
      },
      "source": [
        "## Karakter alap√∫ tokeniz√°ci√≥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UxwXHBNH0h9",
        "outputId": "82b1ed77-4707-4b59-82c3-311297aaf39d"
      },
      "outputs": [],
      "source": [
        "sentence = \"I would like to work than machine lerning engineer at Google!\".lower()\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXXJYDazH8_6",
        "outputId": "388cab9e-1a07-4a34-e856-576be66a1695"
      },
      "outputs": [],
      "source": [
        "sentence = sentence.replace(\" \",\"\")\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES5i9DKpH-RJ",
        "outputId": "3129e5a6-3588-4870-802d-7016a0045f39"
      },
      "outputs": [],
      "source": [
        "chars = [char for char in sentence]\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N39djy2yH_54",
        "outputId": "785bc4b1-0940-473d-a0e5-ba5e9483bff8"
      },
      "outputs": [],
      "source": [
        "chars = list(set(chars))\n",
        "print(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCKUpLPXIEQh",
        "outputId": "60a6510d-ec51-4cf8-e3d3-3db86bec6f6f"
      },
      "outputs": [],
      "source": [
        "word_to_idx = {chars[i] : i for i in range(len(chars))}\n",
        "word_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmZJ8OIYH0h_"
      },
      "source": [
        "## WordLevel alap√∫ tokeniz√°ci√≥\n",
        "\n",
        "Ez a ‚Äûklasszikus‚Äù tokeniz√°ci√≥s algoritmus. Egyszer≈±en lek√©pezheti a szavakat az azonos√≠t√≥kra an√©lk√ºl, hogy b√°rmi k√ºl√∂n√∂sebb lenne. Ennek az az el≈ënye, hogy nagyon egyszer≈±en haszn√°lhat√≥ √©s √©rthet≈ë, de a j√≥ lefedetts√©ghez rendk√≠v√ºl nagy sz√≥kincsre van sz√ºks√©g. Ez a modell nem fog k√∂zvetlen√ºl v√°lasztani, egyszer≈±en lek√©pezi a bemeneti tokeneket az azonos√≠t√≥kra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbzGOpXlx_r"
      },
      "source": [
        "### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SwxpC32KCX0",
        "outputId": "62b4763a-3016-47b5-9d75-821e4e3b1081"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hRbPCKI3DI",
        "outputId": "56fc4f0f-bcac-4dbf-ea60-1a5a38704f28"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
        "word_tokenize(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0osPsKnql1lk"
      },
      "source": [
        "### Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHOdUyeGl_Yu",
        "outputId": "553c5db1-6cf2-452a-aff8-974aed076dac"
      },
      "outputs": [],
      "source": [
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "pre_tokenizer = Whitespace()\n",
        "pre_tokenizer.pre_tokenize_str(\"Hello! How are you? I'm fine, thank you.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2-jPwkBKRwg"
      },
      "source": [
        "## BPE\n",
        "\n",
        "Az egyik legn√©pszer≈±bb alsz√≥ tokeniz√°ci√≥s algoritmus. A Byte-Pair-Encoding √∫gy m≈±k√∂dik, hogy karakterekkel kezd≈ëdik, mik√∂zben a leggyakrabban l√°that√≥kat egyes√≠ti, √≠gy √∫j tokeneket hoz l√©tre. Ezut√°n iterat√≠van dolgozik, hogy √∫j tokeneket √©p√≠tsen a korpuszban l√°that√≥ leggyakoribb p√°rokb√≥l. A BPE olyan szavakat tud fel√©p√≠teni, amelyeket soha nem l√°tott t√∂bb r√©szsz√≥ token haszn√°lat√°val, ez√©rt kisebb sz√≥kincsre van sz√ºks√©ge, √©s kisebb az es√©lye annak, hogy ‚Äûunk‚Äù (ismeretlen) tokenjei vannak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHCtVEMZnuMz",
        "outputId": "39039f96-8772-4dd7-8c38-1c736c3b3c2b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn35koGHiBry",
        "outputId": "e86b1e14-3f06-4efa-df82-1665e81569fd"
      },
      "outputs": [],
      "source": [
        "corpus = dataset[\"train\"][\"text\"] + dataset[\"test\"][\"text\"] + dataset[\"validation\"][\"text\"]\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfE97fmlH0iC"
      },
      "source": [
        "### Speci√°lis tokenek\n",
        "- [UNK] ismeretlen token jel√∂l√©se\n",
        "- [CLS] teljes mondatot reprezent√°l√≥ token\n",
        "- [SEP] mondat szepar√°tor token\n",
        "- [PAD] padding token a fix input hossz felt√∂lt√©s√©t biztos√≠t√≥ token\n",
        "- [MASK] Maszkol√°st biztos√≠t√≥ token. pl.: \"Hello I'm a [MASK] model.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__JcBiSuH0iD",
        "outputId": "7e071386-7c5e-4154-9af0-e0e345bdcc12"
      },
      "outputs": [],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyhIAhd3H0iE",
        "outputId": "f0345056-bef4-4734-c2e3-76ce8150f1a4"
      },
      "outputs": [],
      "source": [
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "print(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ-RLtF-H0iG"
      },
      "outputs": [],
      "source": [
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "tokenizer.pre_tokenizer = Whitespace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "AjyQtZ7XH0iI",
        "outputId": "f305737a-b378-47ae-e9cf-ca51962fe2c0"
      },
      "outputs": [],
      "source": [
        "tokenizer.train_from_iterator(corpus, trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unjPa0WgH0iJ"
      },
      "outputs": [],
      "source": [
        "tokenizer.save(\"tokenizer-bpe-wiki.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm2-G6y9H0iL"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer.from_file(\"tokenizer-bpe-wiki.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "9Nw7lkmTH0iN",
        "outputId": "2105245a-5619-47cf-f7e4-250da8955f83"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.encode(\"Hello, y'all! How are you üòÅ ?\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23IyXe06H0iO",
        "outputId": "b93a0e53-5b44-4b65-e79b-62522a5957d5"
      },
      "outputs": [],
      "source": [
        "print(output.tokens)\n",
        "print(output.ids)\n",
        "print(output.offsets[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLOQavm1H0iO",
        "outputId": "fa177b9c-a4e4-4d52-b458-7d6f0fd1baa3"
      },
      "outputs": [],
      "source": [
        "tokenizer.token_to_id(\"[SEP]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5dcZQmKH0iP"
      },
      "outputs": [],
      "source": [
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "tokenizer.post_processor = TemplateProcessing(\n",
        "    single=\"[CLS] $A [SEP]\",\n",
        "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
        "    special_tokens=[\n",
        "        (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
        "        (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7unTQtzH0iR",
        "outputId": "ad5c26c2-e939-47fc-d5d4-70075b041733"
      },
      "outputs": [],
      "source": [
        "print(output.tokens)\n",
        "output = tokenizer.encode(\"Hello, y'all!\", \"How are you üòÅ ?\")\n",
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPgAEjoaH0iS",
        "outputId": "fc7d1656-2b2d-4b52-ebec-5ca9944b686e"
      },
      "outputs": [],
      "source": [
        "print(output.type_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2gJXlQIH0iT"
      },
      "source": [
        "## Encoding in a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2a-zYcpH0iV"
      },
      "outputs": [],
      "source": [
        "tokenizer.enable_padding(pad_id=3, pad_token=\"[PAD]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vO3V_yLH0iV",
        "outputId": "d551fd9b-73d8-43fd-9225-f2a0629b8b50"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.encode_batch([\"Hello, y'all!\", \"How are you üòÅ ?\"])\n",
        "print(output[0].tokens)\n",
        "print(output[1].tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3M6yvtxH0iW",
        "outputId": "225b8457-c2a7-4af5-a947-80b849f3b1fc"
      },
      "outputs": [],
      "source": [
        "print(output[0].attention_mask)\n",
        "print(output[1].attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMNGhG6dH0iX"
      },
      "source": [
        "## Pretrained tokenizer, haszn√°lata\n",
        "\n",
        "- BERT\n",
        "- WordPiece: Ez a BPE-hez nagyon hasonl√≥ r√©szsz√≥-tokeniz√°ci√≥s algoritmus, amelyet f≈ëk√©nt a Google haszn√°l olyan modellekben, mint a BERT. Moh√≥ algoritmust haszn√°l, amely el≈ësz√∂r hossz√∫ szavakat pr√≥b√°l fel√©p√≠teni. Ez elt√©r a BPE-t≈ël, amely karakterekb≈ël indul ki, √©s min√©l nagyobb tokeneket √©p√≠t. A h√≠res ## el≈ëtagot haszn√°lja a sz√≥ r√©sz√©t k√©pez≈ë jelz≈ëk azonos√≠t√°s√°ra (azaz nem kezd≈ëd≈ë sz√≥)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJLF9mPRrL7L"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://huggingface.co/nlpaueb/legal-bert-base-uncased/raw/main/vocab.txt\"\n",
        "response = requests.get(url)\n",
        "\n",
        "with open(\"bert-vocab.txt\", \"w\") as f:\n",
        "  f.write(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVHdul3xH0iY"
      },
      "outputs": [],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "tokenizer = BertWordPieceTokenizer(\"bert-vocab.txt\", lowercase=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSt6X5NaH0iY",
        "outputId": "d83d040e-5ea0-4b82-aa30-1f4e53d55c60"
      },
      "outputs": [],
      "source": [
        "output = tokenizer.encode(\"Hello, y'all!\", \"How are you üòÅ ?\")\n",
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE_IDEOTskxb"
      },
      "source": [
        "### Saj√°t WordPiece √©p√≠t√©se\n",
        "Ugyan√∫gy mint a BPE-n√©l csak haszn√°ljuk a WordPiece libet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6IP5HEusiA3"
      },
      "outputs": [],
      "source": [
        "from tokenizers.models import WordPiece\n",
        "\n",
        "tokenizerWP = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
        "print(tokenizerWP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb35ERn2kUdK",
        "outputId": "381fee68-adb7-41fa-a8c5-43410469d82a"
      },
      "outputs": [],
      "source": [
        "from tokenizers.trainers import WordPieceTrainer\n",
        "\n",
        "trainerWP = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "print(trainerWP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNmrAO-Gjrij"
      },
      "outputs": [],
      "source": [
        "tokenizerWP.pre_tokenizer = Whitespace()\n",
        "tokenizerWP.train_from_iterator(corpus, trainerWP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBSxLtzGj2KV",
        "outputId": "baf9b39f-8c57-4d3f-fd24-8a1f87851897"
      },
      "outputs": [],
      "source": [
        "output = tokenizerWP.encode(\"Hello, y'all! How are you üòÅ ?\")\n",
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROheze9rtdq4"
      },
      "source": [
        "## Unigram\n",
        "Az Unigram egy r√©szsz√≥ tokeniz√°ci√≥s algoritmus is, √©s √∫gy m≈±k√∂dik, hogy megpr√≥b√°lja azonos√≠tani a legjobb r√©szsz√≥ tokenek k√©szletet, hogy maximaliz√°lja az adott mondat val√≥sz√≠n≈±s√©g√©t. Ez abban k√ºl√∂nb√∂zik a BPE-t≈ël, hogy nem determinisztikus, szekvenci√°lisan alkalmazott szab√°lyok alapj√°n. Ehelyett az Unigram k√©pes lesz t√∂bbf√©le tokeniz√°l√°si m√≥dot kisz√°m√≠tani, mik√∂zben kiv√°lasztja a legval√≥sz√≠n≈±bbet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjAfgDSethc7"
      },
      "outputs": [],
      "source": [
        "from tokenizers.models import Unigram"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "d5f66739f1dd32b1c14636a4c66467b6c7b0f6b88b09a96883d2a49b9cebc250"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
