---
title: "Tokenization"
collection: teaching
type: "M.Sc course"
permalink: /materials/NLP-A/labor/tokenization
venue: "University of Debrecen, Department of Data Science and Visualization"
date: 2025-03-17
location: "Debrecen, Hungary"
---

## [Colab](https://colab.research.google.com/drive/1Z9XA9Ik9ofb_hk61mukq-P1X9JEpv1m4)

Fragmentation of sentences into words, word parts, or characters.

Types:

- Character-based
- Word, subword-based
- Purpose: To break the data set to be processed into words or characters in such a way that the machine learning process used for the analysis can identify them using its own dictionary.
- Trade-off: size vs efficiency