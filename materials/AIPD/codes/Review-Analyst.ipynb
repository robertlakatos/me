{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fcd005-0a74-4a60-8843-427c21374d4d",
   "metadata": {
    "id": "81fcd005-0a74-4a60-8843-427c21374d4d",
    "tags": []
   },
   "source": [
    "# Review Analyst - Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04683de3-1f6f-4797-94e7-b83cba2768c1",
   "metadata": {
    "id": "04683de3-1f6f-4797-94e7-b83cba2768c1"
   },
   "source": [
    "In this notebook, you'll build an AI-powered document analyst, capable of performing **sentiment analysis** and generating data for downstream tasks. You will learn how to employ **few-shot learning** with a language model by providing it with instructive examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a78b9-482c-4908-a8e8-0d47b65c7a14",
   "metadata": {
    "id": "f15a78b9-482c-4908-a8e8-0d47b65c7a14"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388db68b-72f2-411c-b2d1-8d14b4595862",
   "metadata": {
    "id": "388db68b-72f2-411c-b2d1-8d14b4595862"
   },
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- Perform **sentiment analysis** on unstructured text using Phi-3.\n",
    "- Explain what the Phi-3 **prompt template** is, and how it was used during **instruction fine-tuning**.\n",
    "- Guide and improve model performance using **few-shot learning**.\n",
    "- Use Phi-3 to generate JSON data for potential use in downstream processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xh4DpVykxJtf",
   "metadata": {
    "id": "xh4DpVykxJtf"
   },
   "source": [
    "# <FONT COLOR=\"purple\">Verify that the runtime environment is GPU in Colab!</FONT>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1MDXsdoSxPfN",
   "metadata": {
    "id": "1MDXsdoSxPfN"
   },
   "source": [
    "## Install Dependencie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fwmeAtB0xNUc",
   "metadata": {
    "id": "fwmeAtB0xNUc"
   },
   "outputs": [],
   "source": [
    "# The 'device_map' paramter requires Accelerate package.\n",
    "# Restart workspace after the install!\n",
    "!pip install accelerate flash_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5785bb-fd00-4f29-bd6e-48fd893b1888",
   "metadata": {
    "id": "0b5785bb-fd00-4f29-bd6e-48fd893b1888"
   },
   "source": [
    "## Create Microsoft [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4939afbd-23ca-4db8-b12b-209c224ee4ab",
   "metadata": {
    "id": "4939afbd-23ca-4db8-b12b-209c224ee4ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# Microsoft Phi-3-mini-4k-instruct model\n",
    "model = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# The tokenizer is responsible for converting the text into a format understandable by the model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(model, \n",
    "                                             torch_dtype=torch.float16, \n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             attn_implementation=\"eager\")\n",
    "\n",
    "# The task of the streamer object is to ensure that the model's response is continuous. This reduces the waiting time.\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed9f47-4a60-4b0a-8a57-172158e05608",
   "metadata": {
    "id": "89ed9f47-4a60-4b0a-8a57-172158e05608"
   },
   "source": [
    "## Generate Functions\n",
    "\n",
    "In this notebook, we will use the following `generate` function to support our interaction with the LLM.\n",
    "\n",
    "```python\n",
    "# Microsoft Phi-3-mini-4k-instruct default prompt template\n",
    "\n",
    "<|system|>\n",
    "{system}<|end|>\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|> \n",
    "{response}<|end|>\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|> \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51268c1a-1ccd-4f03-bdd8-e6e0b0af5fbf",
   "metadata": {
    "id": "51268c1a-1ccd-4f03-bdd8-e6e0b0af5fbf"
   },
   "outputs": [],
   "source": [
    "def generate(question, system=None, history=[], model=model, max_new_tokens = 256, do_sample=False, temperature=1):\n",
    "    \"\"\"\n",
    "    This function facilitates the generation of text responses leveraging a designated large language model (LLM) pipeline.\n",
    "    It accepts a prompt as input and transmits it to the specified LLM pipeline to produce a textual output.\n",
    "    The function offers comprehensive control over the generative process through the inclusion of configurable parameters and keyword arguments.\n",
    "\n",
    "    - question (str): This parameter holds the user question or any other instruction.\n",
    "    - system (str): This parameter holds contextual information to be provided to the language model for all conversations.\n",
    "    - history (array, opitonal) - This parameter stores the chat history. Each tuple within the list comprises a question and the corresponding assistant response.\n",
    "    - model (object): This object contains the model.\n",
    "    - max_new_tokens (int, optional) — The maximum numbers of tokens to generate, ignoring the number of tokens in the prompt.\n",
    "    - do_sample (bool, optional, defaults to False) — Whether or not to use sampling ; use greedy decoding otherwise.\n",
    "    - temperature (float, optional, defaults to 1.0) — The value used to modulate the next token probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    if system is None:\n",
    "        system = \"\"\"This is a chat between a user and an artificial intelligence assistant.\n",
    "        The assistant gives helpful, detailed, and polite answers to the user's questions based on the context.\n",
    "        The assistant should also indicate when the answer cannot be found in the context.\"\"\"\n",
    "\n",
    "    prompt = f\"<|system|>\\n{system}<|end|>\\n\"\n",
    "\n",
    "    # Add each example from the history to the prompt\n",
    "    for prev_question, prev_response in history:\n",
    "        prompt += f\"<|user|>{prev_question}<|end|>\\n<|assistant|>{prev_response}<|end|>\\n\"\n",
    "    \n",
    "    # Add the user_message prompt at the end\n",
    "    prompt += f\"<|user|>{question}<|end|>\\n<|assistant|>\"\n",
    "    tokenized_prompt = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    outputs = model.generate(input_ids=tokenized_prompt.input_ids,\n",
    "                             max_new_tokens=max_new_tokens,\n",
    "                             streamer=streamer,\n",
    "                             temperature=1, \n",
    "                             do_sample=do_sample)\n",
    "\n",
    "    # Return the decoded text from outputs\n",
    "    return tokenizer.decode(outputs[0][tokenized_prompt.input_ids.shape[-1]:], skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d2548-a72f-4b43-9c00-2525004c91f9",
   "metadata": {
    "id": "e16d2548-a72f-4b43-9c00-2525004c91f9"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c8e9d-f25f-4dcf-8fa9-7afa611a9aef",
   "metadata": {
    "id": "853c8e9d-f25f-4dcf-8fa9-7afa611a9aef",
    "tags": []
   },
   "source": [
    "### Movie reviews from ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78c172-41c1-4468-9719-e953d4f55c8b",
   "metadata": {
    "id": "8a78c172-41c1-4468-9719-e953d4f55c8b"
   },
   "source": [
    "**Neutral**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bda9b4-1eff-47fd-96a2-9afbf2eab339",
   "metadata": {
    "id": "87bda9b4-1eff-47fd-96a2-9afbf2eab339",
    "tags": []
   },
   "outputs": [],
   "source": [
    "neutral = \"\"\"\n",
    "The Matrix\" is a fictional movie delving into intricate subjects like reality, identity, and existence.\n",
    "Released in 1999, it falls within the science fiction action genre and serves as the inaugural entry in the Matrix film series.\n",
    "Directed and written by the Wachowskis, the film features a cast including Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f05f3a-40b6-4c62-b11c-9aa7de83e116",
   "metadata": {
    "id": "90f05f3a-40b6-4c62-b11c-9aa7de83e116"
   },
   "source": [
    "Let's start our exploration by instructing the model to conduct sentiment analysis, guiding us in discerning the overarching sentiment within one of our reviews. Our goal is to elicit from the model a succinct response encapsulated in a single word, indicating whether the sentiment conveyed is *positive*, *negative*, or *neutral*.\n",
    "\n",
    "However, it's important to note that the forthcoming output from the following cell may appear peculiar or unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2TXZl7lb6Vqi",
   "metadata": {
    "id": "2TXZl7lb6Vqi"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of the following movie review: {neutral}\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370c6c9-dac5-4699-97f0-8a50f41ca318",
   "metadata": {
    "id": "f370c6c9-dac5-4699-97f0-8a50f41ca318"
   },
   "source": [
    "Since our objective is to elicit a single-word and exact response from the model, let's refine our prompt further to provide specific guidance regarding the desired response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8becd-feac-4749-b5d5-7e988569e41d",
   "metadata": {
    "id": "c5d8becd-feac-4749-b5d5-7e988569e41d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of the following movie review.: {neutral}?\n",
    "\n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76de73b-dc35-4590-8838-ebe8cb44e982",
   "metadata": {
    "id": "d76de73b-dc35-4590-8838-ebe8cb44e982"
   },
   "source": [
    "The answer is shorter, but still not exact. Let's try to support the model in solving the task. Success may just depend on the use of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a67f9-fca5-413a-a945-649ecd5331d0",
   "metadata": {
    "id": "948a67f9-fca5-413a-a945-649ecd5331d0"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of the following movie review. \n",
    "Pay attention to the fact that if there are no strong mood indicators in the text, then it is neutral.\n",
    "Review: {neutral}?\n",
    "\n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67981387-132c-4cd7-9faf-6f1b89ce7d60",
   "metadata": {
    "id": "67981387-132c-4cd7-9faf-6f1b89ce7d60"
   },
   "source": [
    "Try the **positive** and **negative** cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XcLwUWSZEWif",
   "metadata": {
    "id": "XcLwUWSZEWif"
   },
   "outputs": [],
   "source": [
    "negative = \"\"\"\n",
    "The Matrix\" disappoints on multiple fronts, failing to live up to its lofty expectations.\n",
    "Despite its ambitious premise, the film falls short with its overindulgent reliance on flashy visuals and convoluted storytelling.\n",
    "The characters lack depth, leaving audiences disconnected from their plight, while the philosophical themes feel superficially explored.\n",
    "Moreover, the excessive use of slow-motion action sequences becomes tiresome rather than exhilarating.\n",
    "Ultimately, \"The Matrix\" is a shallow and overhyped spectacle that fails to deliver on its promise of profound sci-fi storytelling.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7609f-74b2-444a-ac5d-d1b62ffb4a01",
   "metadata": {
    "id": "7bf7609f-74b2-444a-ac5d-d1b62ffb4a01"
   },
   "source": [
    "Fill the curly brackets with the negative (variable named `negative`) content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e58aa2-408c-49cb-b9ac-e53ef7e7f1b3",
   "metadata": {
    "id": "16e58aa2-408c-49cb-b9ac-e53ef7e7f1b3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of the following movie review.: {}?\n",
    "\n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MjfPsQxlEaOS",
   "metadata": {
    "id": "MjfPsQxlEaOS"
   },
   "outputs": [],
   "source": [
    "positive = \"\"\"\n",
    "The Matrix\" is an absolute masterpiece of science fiction cinema.\n",
    "Directed by the visionary Wachowskis, this film immerses audiences in a mind-bending world of stunning visuals, gripping action, and profound philosophical depth.\n",
    "From its groundbreaking special effects to its thought-provoking exploration of reality and free will, \"The Matrix\" continues to captivate viewers with its timeless brilliance.\n",
    "A true cinematic landmark that remains as thrilling and relevant today as it was upon its release.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "npTnHn2nEhSg",
   "metadata": {
    "id": "npTnHn2nEhSg"
   },
   "source": [
    "Fill the curly brackets with the positive (variable named `positive`) content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e551d12-88fb-4188-9c7f-140fea141b31",
   "metadata": {
    "id": "9e551d12-88fb-4188-9c7f-140fea141b31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of the following movie review.: {}?\n",
    "\n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f6d7b4-ca76-4588-86b4-1f9f87f38c85",
   "metadata": {
    "id": "b6f6d7b4-ca76-4588-86b4-1f9f87f38c85"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dda3e-479a-4120-8df2-16de33fb4907",
   "metadata": {
    "id": "a75dda3e-479a-4120-8df2-16de33fb4907"
   },
   "source": [
    "Our current prompt lacks the assurance of eliciting meaningful responses from the model. To enhance the reliability and trustworthiness of our outputs, let's pivot our focus to an essential technique: few-shot learning. This approach empowers us to furnish instructive examples to the model, guiding it towards the desired behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1989ec-f6ba-463a-acfe-0047a1eb628e",
   "metadata": {
    "id": "2c1989ec-f6ba-463a-acfe-0047a1eb628e"
   },
   "source": [
    "## Few-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4167b3-3cf0-42c7-aab8-7a9872a7dd71",
   "metadata": {
    "id": "cc4167b3-3cf0-42c7-aab8-7a9872a7dd71"
   },
   "source": [
    "The technique we're discussing varies based on the number of examples we provide, ranging from **one-shot** learning to **many-shot** learning and even **one-to-many-shot** learning. In each instance, a shot represents an example **prompt/response** cycle given to the model to steer its behavior.\n",
    "\n",
    "These shots are usually included before the primary prompt for which we seek the model's response. Different models may require specific formatting of our shots to ensure the model grasps that we're presenting **prompt/response** instances for its guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65088138-500f-4af3-b27e-d8fded21e835",
   "metadata": {
    "id": "65088138-500f-4af3-b27e-d8fded21e835"
   },
   "source": [
    "### Instruction Fine-tuned (Chat) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42afbd-36d8-4d91-b09d-8de021e7c081",
   "metadata": {
    "id": "ff42afbd-36d8-4d91-b09d-8de021e7c081"
   },
   "source": [
    "If you've ever explored model repositories like those on [Hugging Face](https://huggingface.co/meta-llama), you might have come across variants labeled with \"-Instruct or -chat\". These models, such as Llama-2-13b-chat or Llama3-8b-Instruct, undergo additional training beyond their base pretrained counterparts (like Llama-3-70b). This supplementary training, known as instruction fine-tuning, aims to enhance the models' ability to follow instructions, particularly for use in chat applications.\n",
    "\n",
    "While pretrained Language and Logic Model base models are adept at generating text by predicting the most probable continuation given an input, this doesn't equate to effectively responding to questions or instructions.\n",
    "\n",
    "Instruction fine-tuning involves training models on a vast array of example interactions between users and the model itself. This process enables the model to learn how to appropriately follow instructions or engage in dialogue within a chat context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d59d1-d320-420c-9c96-d2fa075b499a",
   "metadata": {
    "id": "649d59d1-d320-420c-9c96-d2fa075b499a"
   },
   "source": [
    "### [Microsoft Phi-3-mini-4k-instruct default prompt template](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde455d-27ed-4806-b0e3-f9f465989bc6",
   "metadata": {
    "id": "0fde455d-27ed-4806-b0e3-f9f465989bc6"
   },
   "source": [
    "The instruction fine-tuning process varies depending on the specific chat variant model being utilized. These models are trained on example interactions formatted according to a template known as the prompt template. You can usually locate the prompt template for a particular model in its documentation.\n",
    "\n",
    "Here's an example of the NVIDIA Phi-3 prompt template. This version provided is slightly simplified, as it excludes a component that we'll delve into later in the course.\n",
    "\n",
    "```python\n",
    "<|system|>\n",
    "{system}<|end|>\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|> \n",
    "{response}<|end|>\n",
    "<|user|>\n",
    "{question}<|end|>\n",
    "<|assistant|>\n",
    "```\n",
    "\n",
    "- **<|system|>system<|end|>:** Specifies the role for the following message, i.e. “system” You are a helpful AI assistant for travel tips and recommendations: The system message\n",
    "- **<|user|>question<|end|>:** Specifies the role for the following message i.e. “user”\n",
    "- What can you help me with?: The user message\n",
    "- **<|assistant|>response<|end|>:** Ends with the assistant header, to prompt the model to start generation.\n",
    "\n",
    "[An example dataset to the Phi-3 fine-tune with a prompt template](https://huggingface.co/datasets/ndavidson/sft-phi-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dbfb02-5e03-45b7-9f6b-ce2a31de6c39",
   "metadata": {
    "id": "92dbfb02-5e03-45b7-9f6b-ce2a31de6c39"
   },
   "source": [
    "### One-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3aba2-72b9-44ca-b329-a0d77dd97d5e",
   "metadata": {
    "id": "c7d3aba2-72b9-44ca-b329-a0d77dd97d5e"
   },
   "source": [
    "Let's briefly step away from our sentiment analysis task, and use a simple text generation prompt to explore how we can use the `generate` function to provide an instructive example, or put another way, perform **one-shot learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05349fdc-ce30-4174-8c3e-491c2c4773d2",
   "metadata": {
    "id": "05349fdc-ce30-4174-8c3e-491c2c4773d2"
   },
   "source": [
    "The function `generate` provided earlier integrates a single user/model interaction enclosed within tags, following the Phi-3 prompt template.  What if we have more interactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85ac90-b4ff-4dec-9840-36100fa44121",
   "metadata": {
    "id": "4d85ac90-b4ff-4dec-9840-36100fa44121"
   },
   "outputs": [],
   "source": [
    "previous_prompt = \"Give me an all uppercase color that starts with the letter 'B'.\"\n",
    "previous_response = \"BLACK\"\n",
    "\n",
    "# The function expects all prompt/response 2-tuples to be in a list\n",
    "instruction = [(previous_prompt, previous_response)]\n",
    "\n",
    "# This is the \"main\" prompt we actually want the model to respond to\n",
    "prompt = \"Give me an all uppercase color that starts with the letter 'P'.\"\n",
    "\n",
    "# Use `prompt_with_examples` to create a one-shot learning prompt, with a single example prepended to our main prompt\n",
    "_ = generate(prompt, history=instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c290bf-8940-48f1-aaaf-971a1d562d0e",
   "metadata": {
    "id": "c8c290bf-8940-48f1-aaaf-971a1d562d0e"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78cfb00-37d0-43ec-8781-af39f626eb37",
   "metadata": {
    "id": "b78cfb00-37d0-43ec-8781-af39f626eb37"
   },
   "source": [
    "## Sentiment Analysis Again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa5cfe-db99-407b-a87c-2d0b49860f86",
   "metadata": {
    "id": "fcfa5cfe-db99-407b-a87c-2d0b49860f86"
   },
   "source": [
    "Given our previous uncertainty regarding the model's ability to accurately classify a neutral review in our sentiment analysis task, let's apply the concept of one-shot learning that we've just covered. This involves providing the model with an instructive example of how to respond to what we, as humans, perceive as a neutral review.\n",
    "\n",
    "Here's an example of a review we want to be classified as neutral. Despite containing elements of both positive and negative sentiments about the movie review, it does not lean significantly towards either extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7bd41-1da5-4485-9041-63bc260f46ab",
   "metadata": {
    "id": "5fd7bd41-1da5-4485-9041-63bc260f46ab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "neutral_1 = f\"\"\"The Matrix (1999) is a sci-fi action film that dives into the mind-bending concept of reality.  \n",
    "The story follows hacker Neo, who uncovers the truth: the world he lives in is a simulated reality called the Matrix.  \n",
    "The film's action sequences are impressive, with the now-famous \"bullet time\" effect becoming a pop culture staple.  \n",
    "While the plot can get intricate, there's no denying the film's ambition and its influence on sci-fi cinema.  \n",
    "This is a solid choice for those looking for a visually stylish action film with a philosophical twist.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8865b94-4736-4071-8434-e9b13318db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of this review {neutral_1}?\n",
    "\n",
    "If a review is not extremely positive, please always be neutral. \n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zcm8Iwk3MG76",
   "metadata": {
    "id": "Zcm8Iwk3MG76"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c1e60-fe03-41ae-90f0-1ffc3e236956",
   "metadata": {
    "id": "7a4c1e60-fe03-41ae-90f0-1ffc3e236956"
   },
   "source": [
    "## Two-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf121c2-9846-4324-91a0-410cbb55dbfa",
   "metadata": {
    "id": "9bf121c2-9846-4324-91a0-410cbb55dbfa"
   },
   "source": [
    "Frequently, when **one-shot learning** falls short of achieving the desired behavior, we can augment the process by introducing additional examples to reinforce the model's understanding.\n",
    "\n",
    "In our scenario, alongside the neutral example we've provided the model, let's also furnish it with an example of a positive review. This additional example aims to clarify the distinction between the two sentiments, thereby aiding the model in making more accurate classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466417ad-85ed-42e1-863a-f4b2046ef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_2 = f\"\"\"The Matrix is a 1999 sci-fi action flick that asks the question: 'What is real?' \n",
    "Keanu Reeves delivers a solid performance as Neo, a computer hacker drawn into a world of rebellion against machines.  \n",
    "The action choreography is innovative, and the special effects, particularly the \"bullet time\" sequences, hold up well even today.  \n",
    "While the philosophical elements can be a bit heavy-handed, the film's exploration of reality and free will is thought-provoking.  \n",
    "Overall, The Matrix is an entertaining and visually striking action film with a unique concept.\"\"\"\n",
    "\n",
    "instruction =  [(neutral_1, \"neutral\")]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of this review {neutral_2}?\n",
    "\n",
    "If a review is not extremely positive, please always be neutral. \n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt, history=instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585eb85-58a9-4d25-8c8e-8404ff1af149",
   "metadata": {},
   "source": [
    "We are now trying to remind the model directly that she has already rated this review as neutral. This is a direct solution, but the point is to understand how past instructions and actions affect the future behavior of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd1e69a-e049-4bc0-9b4e-a535f7886b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_2 = f\"\"\"The Matrix is a 1999 sci-fi action flick that asks the question: 'What is real?' \n",
    "Keanu Reeves delivers a solid performance as Neo, a computer hacker drawn into a world of rebellion against machines.  \n",
    "The action choreography is innovative, and the special effects, particularly the \"bullet time\" sequences, hold up well even today.  \n",
    "While the philosophical elements can be a bit heavy-handed, the film's exploration of reality and free will is thought-provoking.  \n",
    "Overall, The Matrix is an entertaining and visually striking action film with a unique concept.\"\"\"\n",
    "\n",
    "instruction =  [(neutral_1, \"neutral\"), (neutral_2, \"neutral\")]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of this review {neutral_2}?\n",
    "\n",
    "If a review is not extremely positive, please always be neutral. \n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt, history=instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71865d91-1ac5-457c-a594-096690a07a3d",
   "metadata": {
    "id": "71865d91-1ac5-457c-a594-096690a07a3d"
   },
   "source": [
    "### Exercise: Perform Two-shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64fc1b-7fda-46f0-ab67-efdee1c5edff",
   "metadata": {
    "id": "9e64fc1b-7fda-46f0-ab67-efdee1c5edff"
   },
   "source": [
    "TODO: Perform **two-shot** learning, providing the model understanding of what is the positive sentiment exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fddc1b-c703-4419-aaaa-b52be5bbcc02",
   "metadata": {
    "id": "d1fddc1b-c703-4419-aaaa-b52be5bbcc02"
   },
   "source": [
    "### Your Work Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d346908-9b38-445a-b0e6-31314c2ab828",
   "metadata": {
    "id": "2d346908-9b38-445a-b0e6-31314c2ab828",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4763b2ae-7531-49b3-9308-061a190fd492",
   "metadata": {
    "id": "4763b2ae-7531-49b3-9308-061a190fd492"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c2e73-dfc7-4082-a8f7-f3851301572d",
   "metadata": {
    "id": "6e1c2e73-dfc7-4082-a8f7-f3851301572d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction =  [(neutral_1, \"positive\"), (neutral_2, \"positive\")]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "What is the overall sentiment of this review {neutral_2}?\n",
    "\n",
    "If a review is not extremely positive, please always be neutral. \n",
    "Answer with only one word! You do not wort more than one word: \"positive\", \"negative\", or \"neutral\".\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt, history=instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25610b-0c1c-48fb-8bcf-2fd1c4160938",
   "metadata": {
    "id": "1a25610b-0c1c-48fb-8bcf-2fd1c4160938"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e878248-8405-49ad-8103-ea7c2eb5b8c0",
   "metadata": {
    "id": "4e878248-8405-49ad-8103-ea7c2eb5b8c0"
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a60b41-a460-4ccf-9608-4916b17e0523",
   "metadata": {
    "id": "c5a60b41-a460-4ccf-9608-4916b17e0523"
   },
   "source": [
    "Now that our model has demonstrated proficiency in sentiment analysis, let's expand its capabilities to generate JSON objects for downstream utilization. These JSON objects will encapsulate the positive and negative aspects of a given review.\n",
    "\n",
    "To initiate this process, we'll commence by refining our prompt. Initially, we'll prompt the model to enumerate the positive and negative points of a review separately. This iterative approach allows us to gradually enhance the model's performance in generating structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hy4mdVPZQB4A",
   "metadata": {
    "id": "hy4mdVPZQB4A"
   },
   "outputs": [],
   "source": [
    "review = \"\"\"\"The Matrix\" is a groundbreaking film that pushes the boundaries of science fiction cinema.\n",
    "Its innovative visual effects and action-packed sequences captivate audiences, immersing them in a thrilling dystopian world.\n",
    "The complex exploration of themes such as reality and identity adds depth to the narrative, prompting thought and discussion long after the credits roll.\n",
    "However, amidst its brilliance, \"The Matrix\" can feel overly convoluted at times, with a plot that may confuse rather than enlighten.\n",
    "Some viewers may find the philosophical themes too heavy-handed, detracting from the overall enjoyment of the film.\n",
    "Additionally, while the action scenes are visually stunning, they occasionally overshadow character development, leaving the protagonists feeling somewhat one-dimensional.\n",
    "In conclusion, \"The Matrix\" is a cinematic marvel that leaves an indelible mark on the genre.\n",
    "Despite its flaws, its ambition and vision set a new standard for sci-fi storytelling, ensuring its place in cinematic history.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c61db3-9b8e-4dcb-bd6f-18eb7e1dfb4c",
   "metadata": {
    "id": "b3c61db3-9b8e-4dcb-bd6f-18eb7e1dfb4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Separate the positive and negative points from the movie review: {review}\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b911c64-88d7-4219-a8c7-eee724efa2ee",
   "metadata": {
    "id": "8b911c64-88d7-4219-a8c7-eee724efa2ee"
   },
   "source": [
    "The model did quite well. Let's iterate now to try to get the model to produce a JSON object for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3dc9cf-6dcf-41a8-b357-797f26ea93b2",
   "metadata": {
    "id": "8b3dc9cf-6dcf-41a8-b357-797f26ea93b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Separate the positive and negative points from the movie review, and use JSON format to output: {review}\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6bbf8a-f762-4867-a6a9-72bbe3a5cfdd",
   "metadata": {
    "id": "1c6bbf8a-f762-4867-a6a9-72bbe3a5cfdd"
   },
   "source": [
    "We try to give more precise instructions. We need double \"{{\" only to string format. Finally, the double \"{{\" equals simple \"{\" in the result string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a351589-8031-4ecf-b335-2d354d9bba0a",
   "metadata": {
    "id": "1a351589-8031-4ecf-b335-2d354d9bba0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Separate the positive and negative points from the movie review. Use keywords! and use following JSON format to output:\n",
    "\n",
    "{{\"Positive statements\": [], \"Negative statements\": []}}\n",
    "\n",
    "Review: {review}\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9K6_aGRQVmsj",
   "metadata": {
    "id": "9K6_aGRQVmsj"
   },
   "source": [
    "TODO: Let's attempt a similar task, but this time, instruct the models to utilize other XML format.\n",
    "\n",
    "Example format:\n",
    "\n",
    "```XML\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<root>\n",
    "  <Positive/>\n",
    "  <Bad/>\n",
    "</root>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J2DLBOk-WOuD",
   "metadata": {
    "id": "J2DLBOk-WOuD"
   },
   "source": [
    "### Your Work Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1irNuxLuWKI2",
   "metadata": {
    "id": "1irNuxLuWKI2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c63c2c52-c7f4-4cc7-a6f6-b4c5e42a1868",
   "metadata": {
    "id": "c63c2c52-c7f4-4cc7-a6f6-b4c5e42a1868"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb4721-11f8-4f0d-ae49-137f0c7e49a3",
   "metadata": {
    "id": "a6eb4721-11f8-4f0d-ae49-137f0c7e49a3"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Separate the positive and negative points from the movie review. Use keywords! and use following XML format to output:\n",
    "\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n",
    "<root>\n",
    "  <Positive/>\n",
    "  <Bad/>\n",
    "</root>\n",
    "\n",
    "Review: {review}\n",
    "\"\"\"\n",
    "\n",
    "_ = generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e79ad7-8bff-438d-aa63-91098ab8cb79",
   "metadata": {
    "id": "e9e79ad7-8bff-438d-aa63-91098ab8cb79"
   },
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00f573-c735-4b49-9c0a-268ddef53d17",
   "metadata": {
    "id": "ef00f573-c735-4b49-9c0a-268ddef53d17",
    "tags": []
   },
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a0eb3-ca0e-4a0b-9883-4c647b2a69a2",
   "metadata": {
    "id": "f70a0eb3-ca0e-4a0b-9883-4c647b2a69a2"
   },
   "source": [
    "In this notebook, we've covered several fundamental concepts:\n",
    "\n",
    "- **Sentiment Analysis:** This involves discerning the mood or sentiment expressed in a given text.\n",
    "- **Instruction Fine-Tuning:** This process enhances a model's performance by providing tailored examples for learning.\n",
    "- **Phi-3 Prompt Template:** It's a structured format designed to guide Phi-3 model responses during instruction fine-tuning.\n",
    "- **Few-shot Learning:** This technique involves providing one-to-many instructive examples to a model, thereby enhancing its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370076b-c9e4-4f1f-970e-d654f87ef3c4",
   "metadata": {
    "id": "2370076b-c9e4-4f1f-970e-d654f87ef3c4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee7b83-5f14-45e2-9958-90fea3374a76",
   "metadata": {
    "id": "caee7b83-5f14-45e2-9958-90fea3374a76",
    "tags": []
   },
   "source": [
    "## Restart the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a6feb-846c-450e-8991-63c3b06392cc",
   "metadata": {
    "id": "e35a6feb-846c-450e-8991-63c3b06392cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb38a50",
   "metadata": {},
   "source": [
    "## <FONT COLOR=\"red\">The notebook is licensed under the Creative [Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)](https://creativecommons.org/). This means that you can freely copy, distribute, and modify the notebook by authors ([Balázs Harangi](https://inf.unideb.hu/dr-harangi-balazs), [András Hajdu](https://inf.unideb.hu/munkatars/4250), and [Róbert Lakatos](https://inf.unideb.hu/lakatos-robert-tanarseged)), but not for commercial purposes. Additionally, if you modify the notebook, you must cite them as the original creators and share the modified version under the same terms.\n",
    "</FONT>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1NzrWdwNX-m0FLaHPqAdFSepIEQUrw856",
     "timestamp": 1716734781425
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:admin]",
   "language": "python",
   "name": "conda-env-admin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
