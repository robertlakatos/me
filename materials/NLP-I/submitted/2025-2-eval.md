---
title: "Submitted videos"
collection: teaching
type: "B.Sc course"
permalink: /materials/NLP-I/submitted/2025-2-eval
venue: "University of Debrecen, Department of Data Science and Visualization"
date: 2025-12-03
location: "Debrecen, Hungary"
---

# Evaluation

## Neptun code(s): S4BMSQ, KCRMSH
- **Recommended grade(s):** 5
- **Textual evaluation:** The submission fulfills all the requirements for a grade of 5. The task is clearly related to text processing, specifically movie genre prediction based on plot summaries. The implementation utilizes text data and incorporates extensive preprocessing and cleaning procedures, including lowercasing, whitespace removal, special character and number removal, HTML tag stripping, stop word removal, and punctuation handling. These cleaning steps are further validated with unit tests, as mentioned in the source code evaluation and corroborated by the video's explanation of unit testing for text cleaning. The project trains and evaluates multiple machine learning models: GloVe embeddings with a Dense layer, CountVectorizer with a Dense layer, and two TF-IDF models (simple and expanded). The models are trained on a training set and evaluated on a test set, with validation sets also used during training. The evaluation is comprehensive, employing metrics like accuracy and loss, and is presented as a benchmark to compare the models. Visualizations, including Word Clouds, PCA, and UMAP, are used to examine the behavior and balance of the data and the model's operation. The video demonstrates the operation of the best-performing model, the TF-IDF Expanded model, through a Gradio interface, showcasing its ability to predict genres for given movie descriptions. The conclusion drawn from the benchmark analysis is consistent and coherent, identifying the TF-IDF Expanded model as the most effective for the task. The source code evaluation and the video presentation are highly consistent, with the video elaborating on the concepts and processes described in the code evaluation, such as the different vectorization techniques (CountVectorizer, TF-IDF, GloVe) and their underlying principles, as well as the model training and evaluation stages. The explanation of concepts like overfitting, underfitting, and the importance of weighted word importance in TF-IDF is accurate and well-presented in the video.


## Neptun code(s): QX4P71
- **Recommended grade(s):** 4
- **Textual evaluation:**
 The submission meets the requirements for a grade of 4. The task is related to text processing, specifically movie review sentiment analysis, and utilizes text data. Several preprocessing and cleaning procedures are implemented, including text cleaning (lowercasing, removing special characters, lemmatization), tokenization (implied by vectorization), vectorization, and data splitting into training and testing sets. A machine learning model (SVM, Naive Bayes, Logistic Regression, Decision Tree) is trained and evaluated on a test dataset. The model is packaged into a web application using Streamlit and demonstrated in the video. Data mining analysis is performed, as indicated by the examination of data balance and the use of visualizations to understand model performance. The video mentions a unit test for text cleaning, which aligns with the requirement for unit tests on preprocessing steps. The model is evaluated using multiple metrics (accuracy, F1-score, precision), and its operation is examined with visualizations (bar plots). The conclusion provided in the code evaluation is consistent with the video's demonstration of model performance comparison. The video and code evaluation are coherent, and the concepts are explained correctly. However, it does not meet the criteria for a grade of 5 as only one model (SVM) is ultimately selected and deployed, and there isn't a complex benchmark comparing at least three different models with a clear selection process based on validation set performance before final testing. While multiple models were trained, the benchmark aspect for selecting the *best* model among at least three is not as robust as required for a 5.
-------------------

## Neptun code(s): A9ATIE, JE1WAQ
- **Recommended grade(s):** 5
- **Textual evaluation:**
 The submission fulfills all requirements for a grade of 5. The project is a text processing task that utilizes text data for implementation, specifically SMS spam detection. It incorporates several preprocessing and cleaning procedures, including text cleaning (lowercasing, punctuation removal, URL/email/number removal), tokenization, and TF-IDF vectorization. A machine learning model (BiLSTM) and several classical models (Naive Bayes, Logistic Regression, Linear SVC) were trained and evaluated. The evaluation is comprehensive, using multiple metrics like accuracy, precision, recall, F1-score, confusion matrices, and ROC curves. Visualizations are used to examine model performance, with 15 visualizations mentioned. Data mining analysis was performed to examine data behavior and balance, as evidenced by the discussion of class imbalance and its impact on classification. Unit tests were included to verify different pipeline components, including preprocessing and model loading, and all tests passed. The project builds at least three different models (Naive Bayes, Logistic Regression, Linear SVC, and BiLSTM are all discussed and compared), and they are evaluated in a benchmark manner. The best model (Linear SVM) was selected based on validation performance and its final performance was evaluated on a test dataset. A coherent conclusion is provided, recommending Linear SVC for production due to its performance and efficiency, while acknowledging the insights gained from the BiLSTM model. The video presentation and source code evaluation are consistent, with both highlighting the same models, preprocessing steps, evaluation metrics, and the final web application. The concepts and explanations are correct, demonstrating a strong understanding of NLP and machine learning principles.
-------------------

## Neptun code(s): T8XGO6, L5B771
- **Recommended grade(s):** 5
- **Textual evaluation:**
 The submission meets all the requirements for a grade of 5. The project is a text processing task that utilizes text data, specifically the Banking77 dataset, for intent classification. It successfully implements several preprocessing and cleaning procedures, including lowercasing, punctuation removal, tokenization, stop word removal, lemmatization, and TF-IDF vectorization with n-grams. A machine learning model (Logistic Regression) is trained and evaluated on a test dataset. The model's operation is demonstrated through a chatbot application, as shown in the video. Furthermore, the project includes data mining analysis with visualizations such as intent distribution, word clouds, and PCA/t-SNE clusters, which help examine the data's behavior and balance. Unit tests are provided for key preprocessing components like cleaning, preprocessing, and vectorization, ensuring their correctness. The model is evaluated using multiple metrics (accuracy, f1-weighted, f1-macro) and its performance is visualized. Crucially, the project builds and benchmarks at least three different models (Logistic Regression, Multinomial Naive Bayes, and Random Forest Classifier), comparing their performance on validation and test sets. A coherent conclusion is drawn, identifying Logistic Regression with n-grams as the best performing model. The code and video are consistent, with the video clearly demonstrating the application's functionality and explaining the code's pipeline, including the preprocessing, model training, evaluation, and benchmarking stages. The explanations of concepts like TF-IDF and model evaluation are accurate.
-------------------

## Neptun code(s): GO1IHI
- **Recommended grade(s):** 5
- **Textual evaluation:**
 The submission meets all the requirements for a grade of 5. The task is clearly related to text processing, specifically sentiment analysis of movie reviews, and utilizes text data. The project includes a comprehensive set of preprocessing and cleaning procedures such as text cleaning, tokenization, stop word removal, lemmatization, and TF-IDF vectorization. Multiple machine learning models (Multinomial Naive Bayes, Logistic Regression, Random Forest, and LSTM) were trained and evaluated. The evaluation was performed using several metrics including Accuracy, Precision, Recall, F1-Score, Confusion Matrix, ROC Curve, and AUC, and the models were benchmarked to select the best performing one (Logistic Regression). Visualizations were used to examine the model's operation, and data mining analysis was performed to understand the data's behavior. Unit tests were implemented for each text preprocessing function, and an integration test validated the entire pipeline. The best model's performance was evaluated on a test dataset, and a coherent conclusion was provided based on the benchmark results. The project is packaged into an application (Streamlit) and its operation is demonstrated in the video. The video presentation and the source code evaluation are consistent, detailing the same steps, models, and findings. The explanation of concepts is accurate, and the overall implementation is thorough.

## Neptun code(s): WCD2M3, MKRHR0
- **Recommended grade(s):** 4
- **Textual evaluation:**
 The submission meets the requirements for a grade of 4. The project is a text processing task that utilizes text data for implementation, specifically for fake news detection. It includes several preprocessing and cleaning procedures such as lowercasing, URL removal, number and punctuation removal, and whitespace cleanup, followed by feature engineering (word count, character count) and TF-IDF vectorization. A machine learning model (Logistic Regression, Random Forest, and a TensorFlow Neural Network) was trained and evaluated on test data. The video demonstrates the operation of the model in a console application, allowing real-time prediction. Data mining analysis was performed, as indicated by the examination of class distribution and word clouds for real and fake news, and visualizations were used to understand data balance and word importance. The model was evaluated using multiple metrics including accuracy, precision, recall, and F1-score, with confusion matrices and classification reports shown. However, the requirement for unit tests for each preprocessing step was not met, preventing a grade of 5.
-------------------
