{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UM7FEbVWJXj"
      },
      "source": [
        "# Vectorization\n",
        "\n",
        "Magyar:\n",
        "\n",
        "Az NLP (Natural Language Processing) területén a vektorizáció az egyik alapvető lépés, amely során a nyelvi adatokat numerikus formába alakítjuk, hogy algoritmusok számára feldolgozhatóvá váljanak.\n",
        "\n",
        "English:\n",
        "\n",
        "In the field of NLP (Natural Language Processing), vectorization is one of the basic steps in which language data is converted into numerical form so that it can be processed by algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaSq7eQSWJXm"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"The cat is sitting on the table.\",\n",
        "    \"There is a dog lying by the table.\",\n",
        "    \"The dog and the cat are friends, however the dog likes the cat better than the cat likes the dog.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "7ZWOSneLWc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "words = word_tokenize(\" \".join(corpus[:2]).lower())\n",
        "words = list(set(words))\n",
        "\n",
        "vocab = {}\n",
        "for i, word in enumerate(words):\n",
        "    vocab[word] = i\n",
        "\n",
        "print(\"Vocab:\", vocab)"
      ],
      "metadata": {
        "id": "mBXdwOdeWcj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4clYLSPVWJXo"
      },
      "source": [
        "## One-hot Encoding\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*ggtP4a5YaRx6l09KQaYOnw.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oESEHlubWJXq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "words = word_tokenize(\" \".join(corpus[:2]).lower())\n",
        "words = list(set(words))\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "one_hot = lb.fit_transform(list(words))\n",
        "\n",
        "print(\"Classes:\", lb.classes_)\n",
        "print(\"Words:\", list(words))\n",
        "print(\"One-hot vectors:\\n\", one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9jgKQGLWJXs"
      },
      "source": [
        "## Count Vectorization / Bag of Words (BoW)\n",
        "\n",
        "<img src=\"https://user.oc-static.com/upload/2022/12/08/16705125107088_16034397439042_surfin%20bird%20bow.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vX-coKcWJXt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus_lower = [c.lower() for c in corpus]\n",
        "count_vect = CountVectorizer()\n",
        "X_count = count_vect.fit_transform(corpus_lower)\n",
        "\n",
        "print(\"Vocab:\", count_vect.vocabulary_)\n",
        "print(\"Corpus:\", corpus_lower)\n",
        "print(\"Count vectorization:\\n\", X_count.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF\n",
        "\n",
        "Magyar:\n",
        "\n",
        "<b>TF (Term Frequency):</b> Egy adott szó előfordulása a dokumentumban, normalizálva a dokumentum összes szavához képest.\n",
        "\n",
        "<b>IDF (Inverse Document Frequency):</b> Annak a mértéke, hogy egy szó mennyire ritka az egész korpuszban. Ez a korpuszban szereplő dokumentumok számának és azoknak a dokumentumoknak a számának aránya, amelyekben a szó szerepel.\n",
        "\n",
        "English:\n",
        "\n",
        "<b>TF (Term Frequency):</b> Occurrence of a specific word in the document, normalized to all words in the document.\n",
        "\n",
        "<b>IDF (Inverse Document Frequency):</b> A measure of how rare a word is in the entire corpus. It is the ratio of the number of documents in the corpus to the number of documents in which the word appears."
      ],
      "metadata": {
        "id": "_22z5MT3b-yq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Sk-tJpWJXv"
      },
      "source": [
        "### Term Frequency (TF)\n",
        "\n",
        "Magyar:\n",
        "- n = Az összes szószáma a dokumentumban\n",
        "- td = Az adott szó előfordulásainak száma a dokumentumban​\n",
        "- TF(t,d) = n / td\n",
        "\n",
        "English:\n",
        "- n = Total number of words in the document\n",
        "- td = Number of occurrences of the given word in the document\n",
        "- TF(t,d) = n / td"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Dr5-jI-WJXw"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tf_transformer = TfidfTransformer(use_idf=False, norm='l1')\n",
        "X_tf = tf_transformer.fit_transform(X_count)\n",
        "\n",
        "print(\"Term Frequency (TF):\\n\", X_tf.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4QJJhBmWJXx"
      },
      "source": [
        "## Inverse Document Frequency (IDF)\n",
        "\n",
        "Magyar:\n",
        "- D = Összes dokumentum száma.\n",
        "- d = Azoknak a dokumentumoknak a száma amelyek tartalmazzák az adott szót.\n",
        "- IDF(t) = log(D)\n",
        "\n",
        "English:\n",
        "- D = Number of all documents.\n",
        "- d = The number of documents that contain the given word.\n",
        "- IDF(t) = log(D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnOLC8OUWJX0"
      },
      "outputs": [],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_tfidf = tfidf_transformer.fit_transform(X_count)\n",
        "\n",
        "print(\"IDF értékek:\", tfidf_transformer.idf_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiU2ubfNWJX1"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "TD-IDF = TF * IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9FaDYF-WJX2"
      },
      "outputs": [],
      "source": [
        "X_tfidf = tfidf_transformer.fit_transform(X_count)\n",
        "\n",
        "print(\"TF-IDF:\\n\", X_tfidf.toarray())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}