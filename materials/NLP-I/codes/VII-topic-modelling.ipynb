{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ-MSOEHMlAE"
      },
      "source": [
        "# Labor VII. Topic modelleing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmyi_BUZMlAH"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFE28018MlAJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_imdb = pd.read_csv(\"hf://datasets/scikit-learn/imdb/IMDB Dataset.csv\")\n",
        "df_imdb.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjh-FhqkMlAM"
      },
      "outputs": [],
      "source": [
        "df_imdb.info()\n",
        "df_imdb.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text cleaning"
      ],
      "metadata": {
        "id": "qc3_9TNoMzSW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eEkOoiUMMyO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wordcloud"
      ],
      "metadata": {
        "id": "9l3osZXCNPgB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QW7WcZvVM3lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>Hiding Jeno</summary>\n",
        "\n",
        "```python\n",
        "  from wordcloud import WordCloud\n",
        "\n",
        "  long_string = ','.join(df_imdb[\"review\"].values)\n",
        "\n",
        "  wordcloud = WordCloud(background_color=\"white\",\n",
        "                        max_words=1000,\n",
        "                        contour_width=3,\n",
        "                        contour_color='steelblue')\n",
        "\n",
        "  wordcloud.generate(long_string)\n",
        "\n",
        "  wordcloud.to_image()\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "hSeG_Uw2O3bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Dirichlet Allocation (LDA)"
      ],
      "metadata": {
        "id": "kqTbniRMNQle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Dirichlet distribution\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0047259X12001753-gr1.jpg\">"
      ],
      "metadata": {
        "id": "Z9tf5T2pWE3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DJs9JtuSWExy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.corpora as corpora\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_words = [item.split() for item in tqdm(df_imdb[\"review\"].values)]\n",
        "\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "\n",
        "print(id2word)"
      ],
      "metadata": {
        "id": "yNrLRfnyPV4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_imdb[\"review\"].values[0])\n",
        "print(data_words[0][:10], len(data_words[0]))"
      ],
      "metadata": {
        "id": "8z5hPDHNQC9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-Words\n",
        "id2word.doc2bow(data_words[0])"
      ],
      "metadata": {
        "id": "rVo6_cLFRevP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "  <summary>Hiding Jeno</summary>\n",
        "\n",
        "```python\n",
        "  sum([item[1] for item in id2word.doc2bow(data_words[0])])\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "UyGLb7WWR8qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [id2word.doc2bow(text) for text in tqdm(data_words)]"
      ],
      "metadata": {
        "id": "hzBDlSLPP0T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "num_topics = 10\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=10,\n",
        "                                       iterations=10)\n",
        "\n",
        "lda_model.print_topics()"
      ],
      "metadata": {
        "id": "OEKmGyqKPupW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "mZLaepgJThRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_data_filepath = os.path.join('lda_'+str(num_topics))\n",
        "\n",
        "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "with open(LDAvis_data_filepath, 'wb') as f:\n",
        "    pickle.dump(LDAvis_prepared, f)\n",
        "\n",
        "with open(LDAvis_data_filepath, 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)\n",
        "    pyLDAvis.save_html(LDAvis_prepared, 'lda_'+ str(num_topics) +'.html')\n",
        "\n",
        "LDAvis_prepared"
      ],
      "metadata": {
        "id": "UvyXKN2QS-0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}