{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epf5Ib5XQRyg"
   },
   "source": [
    "# Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldWqrACdZcd7"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRkzRO28M6ha",
    "outputId": "8bd4a9c8-a8d0-48bc-ba8b-c2350d56343d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lord_of_the_rings = pd.read_parquet(\"hf://datasets/jeremyarancio/lotr-book/data/train-00000-of-00001-0402ae8116935261.parquet\")\n",
    "lord_of_the_rings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lord_of_the_rings = lord_of_the_rings[\"text\"].values[0].lower()\n",
    "len(lord_of_the_rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "CR0e4jmWTvqN",
    "outputId": "7cef2c19-4557-48d0-a4ec-2f8dcfce86ad"
   },
   "outputs": [],
   "source": [
    "lord_of_the_rings[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltRouz5SZYEY"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0EJx3DuXupe"
   },
   "outputs": [],
   "source": [
    "# prompt: Convert the lord_of_the_rings string varrible to array which consist of characters from string.\n",
    "\n",
    "lord_of_the_rings_array = list(lord_of_the_rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXjHWpmvYGPw",
    "outputId": "52df8f05-5d44-4515-fdb4-43d8238b5f68"
   },
   "outputs": [],
   "source": [
    "lord_of_the_rings_array[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTgDfREBZiLG"
   },
   "source": [
    "## Prepair Train, Val and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stsCMrRQZUbX",
    "outputId": "33c40a73-0429-467c-eecf-f7e78b830ead"
   },
   "outputs": [],
   "source": [
    "# prompt: Chunk the lord_of_the_rings_array with a sliding window.\n",
    "# Lenght of the sliding window should be 50 characters.\n",
    "# Create a 2 dimasional array called X to chunk.\n",
    "# And creat an y varrible which includes the each 50+1 elements.\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "window_size = 50\n",
    "\n",
    "for i in tqdm(range(0, len(lord_of_the_rings_array) - window_size)):\n",
    "  X.append(lord_of_the_rings_array[i:i + window_size])\n",
    "  y.append(lord_of_the_rings_array[i + window_size])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmtvgnTbW3P0",
    "outputId": "1c4d5d86-e09d-4d71-e144-7b95975ce474"
   },
   "outputs": [],
   "source": [
    "# prompt: Split train val and test set from X, y arrays. X is the input and y is the label.\n",
    "# The ratio should be 80% 10% 10% and you dont shuffle the data when you split.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X and y are your input and label arrays\n",
    "\n",
    "train_split = int(0.8 * len(X))\n",
    "val_split = int(0.9 * len(X))\n",
    "\n",
    "X_train = X[:train_split]\n",
    "y_train = y[:train_split]\n",
    "\n",
    "X_val = X[train_split:val_split]\n",
    "y_val = y[train_split:val_split]\n",
    "\n",
    "X_test = X[val_split:]\n",
    "y_test = y[val_split:]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSh9Psf2jRx0",
    "outputId": "a28ba836-49b8-4f35-8cdc-60ce8c3933f2"
   },
   "outputs": [],
   "source": [
    "# Create a character to index mapping\n",
    "char_to_index = {char: index for index, char in enumerate(sorted(list(set(lord_of_the_rings_array))))}\n",
    "index_to_char = {index: char for index, char in enumerate(sorted(list(set(lord_of_the_rings_array))))}\n",
    "\n",
    "# Convert training and validation data to numerical representation\n",
    "X_train_indices = [[char_to_index[char] for char in sequence] for sequence in tqdm(X_train)]\n",
    "y_train_indices = [char_to_index[char] for char in tqdm(y_train)]\n",
    "\n",
    "X_val_indices = [[char_to_index[char] for char in sequence] for sequence in tqdm(X_val)]\n",
    "y_val_indices = [char_to_index[char] for char in tqdm(y_val)]\n",
    "\n",
    "X_test_indices = [[char_to_index[char] for char in sequence] for sequence in tqdm(X_test)]\n",
    "y_test_indices = [char_to_index[char] for char in tqdm(y_test)]\n",
    "\n",
    "X_train_indices = np.array(X_train_indices)\n",
    "y_train_indices = np.array(y_train_indices)\n",
    "\n",
    "X_val_indices = np.array(X_val_indices)\n",
    "y_val_indices = np.array(y_val_indices)\n",
    "\n",
    "X_test_indices = np.array(X_test_indices)\n",
    "y_test_indices = np.array(y_test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0eyWOUZh1fs"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrzLwAJOh3TL",
    "outputId": "3ed41383-f4e4-4acd-dd8a-45e0977fafc0"
   },
   "outputs": [],
   "source": [
    "# prompt: Create an GRU network which can learn to generate the next caracter.\n",
    "# Use the tensorflow librarary. The trainin input is in X_train and label is the y_train.\n",
    "# The validataion dataset are X_val and y_val. Create a test generation a sample text in each epoch\n",
    "# that we can see the performance of model.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(char_to_index)\n",
    "embedding_dim = 128\n",
    "rnn_units = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "    tf.keras.layers.GRU(rnn_units),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ## Training\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    model.fit(X_train_indices, y_train_indices, batch_size=batch_size, epochs=1, validation_data=(X_val_indices, y_val_indices))\n",
    "\n",
    "    # Generate a sample text\n",
    "    start_index = np.random.randint(0, len(X_test_indices) - 1)\n",
    "    # Convert generated_text to a regular Python string\n",
    "    generated_text = \"\".join(X_test[start_index])\n",
    "    ## print(generated_text)\n",
    "    for _ in tqdm(range(100)):\n",
    "        input_sequence = np.array([char_to_index[char] for char in generated_text[-window_size:]])\n",
    "        input_sequence = np.expand_dims(input_sequence, axis=0)\n",
    "\n",
    "        predicted_probabilities = model.predict(input_sequence, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probabilities)\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "\n",
    "        generated_text += predicted_char\n",
    "\n",
    "    print(f\"Generated text:{generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "PZG9_uRQwpRj",
    "outputId": "e1062b80-154e-4692-f8fc-d6cab4f9c063"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywAxRJ8zvsEY"
   },
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjverfY8vu8b",
    "outputId": "f3b52542-5967-453c-cfc0-b81598cc3fb8"
   },
   "outputs": [],
   "source": [
    "# prompt: Create sample code where i can setup the temprature of the generation on the\n",
    "# model prediciton.\n",
    "\n",
    "# ## Temperature\n",
    "\n",
    "def generate_text_with_temperature(model, start_sequence, length, temperature=1.0):\n",
    "    \"\"\"Generates text using the model with temperature.\"\"\"\n",
    "\n",
    "    generated_text = start_sequence\n",
    "    for _ in tqdm(range(length)):\n",
    "        input_sequence = np.array([char_to_index[char] for char in generated_text[-window_size:]])\n",
    "        input_sequence = np.expand_dims(input_sequence, axis=0)\n",
    "\n",
    "        predicted_probabilities = model.predict(input_sequence, verbose=0)[0]\n",
    "\n",
    "        # Apply temperature\n",
    "        predicted_probabilities = np.log(predicted_probabilities) / temperature\n",
    "        probabilities = np.exp(predicted_probabilities) / np.sum(np.exp(predicted_probabilities))\n",
    "\n",
    "        predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
    "        predicted_char = index_to_char[predicted_index]\n",
    "\n",
    "        generated_text += predicted_char\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage with temperature:\n",
    "start_index = np.random.randint(0, len(X_test_indices) - 1)\n",
    "start_sequence = \"\".join(X_test[start_index])\n",
    "temp = 0.7  # Adjust temperature here\n",
    "generated_text = generate_text_with_temperature(model, start_sequence, 100, temperature=temp)  # Adjust temperature here\n",
    "print(f\"Generated text with temperature ({temp}):{generated_text}\")\n",
    "\n",
    "# You can experiment with different temperature values (e.g., 0.2, 0.7, 1.2) to see how it affects the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXwjddWcDqu3"
   },
   "outputs": [],
   "source": [
    "# prompt: create code which save 2 tsv file the embedding layer from the model. The first consist of the characters and the second consist of the vectors to the characters. To separation use '\\t' character in the tsv file.\n",
    "\n",
    "# ... (Your existing code) ...\n",
    "\n",
    "embedding_layer = model.layers[0]\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Create a list to store characters and their corresponding vectors\n",
    "chars = []\n",
    "vectors = []\n",
    "\n",
    "for char, index in list(char_to_index.items())[3:]:\n",
    "  chars.append(char)\n",
    "  vectors.append(embedding_weights[index])\n",
    "\n",
    "chars\n",
    "# Save characters to a TSV file\n",
    "with open(\"chars.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for char in chars:\n",
    "        f.write(f\"{char}\\n\")\n",
    "\n",
    "# Save vectors to a TSV file\n",
    "with open(\"vectors.tsv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for vector in vectors:\n",
    "        vector_str = \"\\t\".join(map(str, vector))  # Join vector elements with tabs\n",
    "        f.write(f\"{vector_str}\\n\")\n",
    "\n",
    "# ... (Rest of your code) ..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
