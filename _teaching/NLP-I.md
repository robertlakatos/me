---
title: "Introduction to Natural Language Text Processing"
collection: teaching
type: "B.Sc course"
permalink: teaching/NLP-I
venue: "University of Debrecen, Department of Data Science and Visualization"
date: 2024-09-05
location: "Debrecen, Hungary"
---

Within the framework of the subject, students will learn about the basics of natural language text processing (NLP). In addition, they also gain practical experience while solving various tasks. Main topics: logistic regression, naive Bayes model, PCA, n-gram models, Word2Vec, classical and recurrent neural networks. Furthermore, during the completion of the subject, students can gain insight into current, modern neural architectures. During the semester, students will also have the opportunity to test and train these architectures on real data using cloud-based services [(Google Collab)](https://colab.google/).

======

## [Email address of the Teacher](mailto:lakatos.robert@inf.unideb.hu)

## Requirements

### Rules

- Attendance sheet: Fewer absences than allowed. Active participation in classes.
- Create a working application, solve a real problem, and present it as a video using the solutions and models learned in class.
     - It must be uploaded to Github and shared.
     - Maximum length of video is 5-10 minutes.
     - In the video, each creator must present their own contribution. (for 3-8 minutes)
     - The application must be shown in action at the end of the video. (for 1-2 minutes)
- Organizing into teams (2-4 people) or working individually.
- If the creator(s) uses a service based on a generative language model to complete the task, they must attach the prompt log to the completed project as additional material.
- It is not certain that the team members receive a uniform grade, but they get grades proportionate to the task they have completed in the project.

### Evaluation

Task | Grade 3 | Grade 4 | Grade 5 
--- | --- | --- | --- 
Data | You need data your project. |  Exploratory data analysis (Visualization) | 
Preprocess | The code should include preprocessing steps. (Text cleaning, Feature Engineering, Tokenization, Vectorization, Training, validation, and test data preparation) | UnitTest, Visualization | 
Model | Train a machine learning model on the data. | | Use more models, at least 3
Evaluate | Evaluate your model on your test data. | Complex Benchmarking |
Application | Package your model into an application. Present the your pipeline and use the technical term / keywords correctly. | | Create a conclusion. Explain how your model works. Present the limitations and opportunities for further development.

### Submission

- **Submission deadline: 2025.12.14. 24:00 (Sunday)**
- [**Submission form**](https://forms.office.com/e/TjTrVVYRCw?origin=lprLink)
     - Mandatory fields: Neptun code, Video link, Source link.
     - If there are more than one of you, the Neptun code can be entered as a list separated by commas.
     - The Source link contains the source code.
     - The Video link contains the video code.
     - If two are the same, the same must be entered in both places.
     - If there are no exceptional obstacles, please allow (chose **'yes'** on the form) your submitted work to be shared among the students of the following semesters within the framework of the subject.

## Labor
 
- N.    [Python Basics](../materials/NLP-I/labor/N-python)
- N.    [Numpy and Matplotlib](../materials/NLP-I/labor/N-numpy-and-matplotlib)
- N.    [Pandas Intro](../materials/NLP-I/labor/N-pandas)
- I.    [Text cleaning I.](../materials/NLP-I/labor/I-text-cleaning-I)
- II.   [Text cleaning II.](../materials/NLP-I/labor/II-text-cleaning-II)
- II.   [Tokenization](../materials/NLP-I/labor/II-tokenization)
- III.  [Vectorization I.](../materials/NLP-I/labor/III-vectorization)
- IV.   [Modeling 1 - Linear Regression (Sentiment Analysis)](../materials/NLP-I/labor/IV-linear-regression)
- V.    [Modeling 2 - Neural Network (Text Classification)](../materials/NLP-I/labor/V-neural-network)
- VI.   [Vectorization II. - Embedding](../materials/NLP-I/labor/VI-embedding)
- VII.  [Text Generator I.](../materials/NLP-I/labor/VII-text-generation)
- VIII. [Topic Modelling](../materials/NLP-I/labor/VIII-topic-modelling)
- IX.   [Text-based Recommendation Systems](../materials/NLP-I/labor/IX-text-based-recommendation-systems)
- X.    [Text Generator II.](../materials/NLP-I/labor/VII-text-generation)
- XI.   [Dependency Parsing, Named-entity recognition / Token Classification](../materials/NLP-I/labor/XI-dependency-parsing-token-classification)
- XII.   [Attention is all you need](../materials/NLP-I/labor/XII-attention-is-all-you-need)

## [Submitted](https://unidebhu-my.sharepoint.com/:x:/r/personal/lakatos_robert_inf_unideb_hu/Documents/Submission%20Form.xlsx?d=w4bea7c59f46b496dbaeed9bb2f3a50e2&csf=1&web=1&e=aMnmoK)

- [2025 Autumn Evaluation](../materials/NLP-I/submitted/2025-2-eval)
- [2024 Autumn Videos](../materials/NLP-I/submitted/2024-2-videos)
- [2023 Autumn Videos](../materials/NLP-I/submitted/2023-2-videos)

## Usefull Links

- [Huggingface](https://huggingface.co/)
- [Keras](https://keras.io/)
- [Tensorflow](https://www.tensorflow.org/)
- [Pytorch](https://pytorch.org/)
- [Pyton](https://www.python.org/)
- [Google Colab](https://colab.google/)

## Recommended Literatures and Courses

1. [Jurafsky, Daniel, and James H. Martin. "Speech and language processing (draft)." Chapter A: Hidden Markov Models (Draft of September 11, 2018). Retrieved March 19 (2018): 2019.](https://ms.b-ok.xyz/book/3560643/4a6ab2)
2. [Eisenstein, Jacob. "Introduction to natural language processing." MIT press, 2019.](https://mitpress.mit.edu/9780262042840/introduction-to-natural-language-processing/)
3. [Goldberg, Yoav. "A primer on neural network models for natural language processing." Journal of Artificial Intelligence Research 57 (2016): 345-420.](https://arxiv.org/pdf/1510.00726.pdf)
4. [Francois Chollet. "Deep Learning with Python"](https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438)
5. [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt)
6. [MIT Introduction to Deep Learning](http://introtodeeplearning.com/)

## [Attendance sheet](https://forms.cloud.microsoft/e/Ek0iSB0fjC?origin=lprLink)

## [Attendance sheet status](https://unidebhu-my.sharepoint.com/:x:/g/personal/lakatos_robert_inf_unideb_hu/EYKe7oC0eTVOkJXg2xjAZWoBENcHlhuEiFHCRYR9SxxmkA?e=ApkACz)